{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <b>Apriori Algorithm to Explore Complementary Items from Small Transactions </b> \n",
    "\n",
    "In this notebook, we are performing Apriori Algorithm to find the complementary items from small transactions. We define a small transaction to be a transaction containing <= 10 items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from operator import itemgetter\n",
    "from time import time\n",
    "import numpy as np\n",
    "import itertools\n",
    "import collections\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>global_transaction_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_num</th>\n",
       "      <th>qty_sold</th>\n",
       "      <th>item_price</th>\n",
       "      <th>qty_is_weight</th>\n",
       "      <th>ticket_num</th>\n",
       "      <th>date</th>\n",
       "      <th>time_scanned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4889</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>2527</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>07:03:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3125</td>\n",
       "      <td>6</td>\n",
       "      <td>460</td>\n",
       "      <td>429</td>\n",
       "      <td>1</td>\n",
       "      <td>2527</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>07:03:34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2528</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>07:04:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2528</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>07:04:25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>7013201045</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>299</td>\n",
       "      <td>0</td>\n",
       "      <td>2529</td>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>07:05:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   global_transaction_id     item_id  dept_num  qty_sold  item_price  \\\n",
       "0                      0        4889         6         3          99   \n",
       "1                      0        3125         6       460         429   \n",
       "2                      1           5        20         4         100   \n",
       "3                      1           2        20         6         100   \n",
       "4                      2  7013201045         1         1         299   \n",
       "\n",
       "   qty_is_weight  ticket_num        date time_scanned  \n",
       "0              0        2527  2020-07-01     07:03:30  \n",
       "1              1        2527  2020-07-01     07:03:34  \n",
       "2              0        2528  2020-07-01     07:04:22  \n",
       "3              0        2528  2020-07-01     07:04:25  \n",
       "4              0        2529  2020-07-01     07:05:06  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data and take a glance\n",
    "df = pd.read_csv(\"../raw_data/ncr/items_transactions.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>description</th>\n",
       "      <th>ecomm_description</th>\n",
       "      <th>category</th>\n",
       "      <th>item_type</th>\n",
       "      <th>upc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAN DULCE SENCILLO</td>\n",
       "      <td>Mexican Sweet Bread/Pan Dulce Mexicano, 1 Count</td>\n",
       "      <td>20101020</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>BOLILLO FRENCH ROLLS</td>\n",
       "      <td>Bolillo, French Rolls, 1 Count</td>\n",
       "      <td>20101210</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>BOLILLO QUESO/CHILE JALAP</td>\n",
       "      <td>Jalapeño and Cheese Bolillo, 1 Count</td>\n",
       "      <td>20101210</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>EMPANADA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20101020</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MIni Bolillo</td>\n",
       "      <td>BOLILLO SMALL, 2 OZ</td>\n",
       "      <td>20101210</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                description  \\\n",
       "0        1         PAN DULCE SENCILLO   \n",
       "1        2       BOLILLO FRENCH ROLLS   \n",
       "2        3  BOLILLO QUESO/CHILE JALAP   \n",
       "3        4                   EMPANADA   \n",
       "4        5               MIni Bolillo   \n",
       "\n",
       "                                 ecomm_description  category  item_type  upc  \n",
       "0  Mexican Sweet Bread/Pan Dulce Mexicano, 1 Count  20101020          0   10  \n",
       "1                   Bolillo, French Rolls, 1 Count  20101210          0   20  \n",
       "2             Jalapeño and Cheese Bolillo, 1 Count  20101210          0   30  \n",
       "3                                              NaN  20101020          0   40  \n",
       "4                              BOLILLO SMALL, 2 OZ  20101210          0   50  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data and take a glance\n",
    "items_descriptions = pd.read_csv(\"../raw_data/ncr/items_descriptions.csv\")\n",
    "items_descriptions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> 1. Data Preprocessing </b>\n",
    "In this section, we first cleaned up the data. More specifically, we did the following tasks:\n",
    "<ul>\n",
    "<li>1.1 Remove all non food items</li>\n",
    "<li>1.2 Reshape the dataframe to have one transaction per row</li>\n",
    "<li>1.3 Extract the input data for the Apriori Algorithm</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.1 Remove all non food items</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out non food items\n",
    "df = df[(df.item_id != 9492206955)] #plastic bag\n",
    "df = df[(df.item_id != 5555)] #BAG EB&W CUSTOMER\n",
    "df = df[(df.item_id != 9746490305)] #JUBILEE BIG ROLL PAPER TOWELS\n",
    "df = df[(df.item_id != 74870310181)] #store_brand paper napkins\n",
    "\n",
    "# remove items containing \"CRV\" in their name\n",
    "items_descriptions[\"CRV?\"] = items_descriptions[\"description\"].apply(lambda x: \"Yes\" if \"CRV\" in x else \"No\")\n",
    "CRVs = items_descriptions[items_descriptions[\"CRV?\"]==\"Yes\"]\n",
    "CRVs = CRVs[\"item_id\"].tolist()\n",
    "\n",
    "for CRV in CRVs:\n",
    "    df = df[(df.item_id != CRV)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.2 Reshape dataframe</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_transaction_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0    4889\\n1    3125\\nName: 0, dtype: int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2    5\\n3    2\\nName: 1, dtype: int64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4    7013201045\\n5    4856406700\\nName: 2, dty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6     7084781116\\n8     7084781116\\n10    7084...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13    20698000000\\n14    20900000000\\n15    20...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 item_id\n",
       "global_transaction_id                                                   \n",
       "0                            0    4889\\n1    3125\\nName: 0, dtype: int64\n",
       "1                                  2    5\\n3    2\\nName: 1, dtype: int64\n",
       "2                      4    7013201045\\n5    4856406700\\nName: 2, dty...\n",
       "3                      6     7084781116\\n8     7084781116\\n10    7084...\n",
       "5                      13    20698000000\\n14    20900000000\\n15    20..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# groupby() to have one transaction per row\n",
    "df2 = df.groupby(\"global_transaction_id\")[\"item_id\"].apply(lambda x: str(x))\n",
    "df2_frame = df2.to_frame()\n",
    "\n",
    "# initial version of new dataframe - needs some preprocessing\n",
    "df2_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = []\n",
    "for index, value in df2.items():\n",
    "    only_item_ids = []\n",
    "    row2 = value.split('Name')[0]\n",
    "    row3 = row2.split('\\n')\n",
    "    for element in row3:\n",
    "        if element != '':\n",
    "            length = len(element.split(' '))\n",
    "            only_item_ids.append(element.split(' ')[length-1])\n",
    "    list_of_lists.append(only_item_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1.3 Extract input data for Apriori</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    alist = x.split(',')\n",
    "    only_numbers = []\n",
    "    for element in alist:\n",
    "        if element != 'None':\n",
    "            if element != '':\n",
    "                only_numbers.append(element)\n",
    "    only_numbers_string = ','.join(only_numbers)\n",
    "    return only_numbers_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of small transactions: 88377\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4889,3125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5,2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7013201045,4856406700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7084781116,7084781116,7084781116,7432309164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20698000000,20900000000,20900000000,2090000000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               items\n",
       "0                                          4889,3125\n",
       "1                                                5,2\n",
       "2                              7013201045,4856406700\n",
       "3        7084781116,7084781116,7084781116,7432309164\n",
       "4  20698000000,20900000000,20900000000,2090000000..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame(list_of_lists)\n",
    "\n",
    "columns = [i for i in range(table.shape[1])]\n",
    "\n",
    "table['items'] = table[columns].apply(lambda row: ','.join(row.values.astype(str)), axis=1)\n",
    "\n",
    "table['items'] = table['items'].apply(lambda x: clean(x))\n",
    "\n",
    "# items is the input data we need for the algorithm\n",
    "data = pd.DataFrame(table['items'])\n",
    "\n",
    "# remove all transactions which have more than 10 items\n",
    "data[\"items list\"] = data[\"items\"].apply(lambda x: x.split(\",\"))\n",
    "data[\"remove?\"] = data[\"items list\"].apply(lambda x: \"YES\" if len(x) > 10 else \"NO\")\n",
    "data_small_transactions = data[data[\"remove?\"] == \"NO\"].reset_index()\n",
    "\n",
    "# store this number\n",
    "num_small_transactions = data_small_transactions.shape[0]\n",
    "\n",
    "# 88,377 transactions with <= 10 items\n",
    "print(\"Number of small transactions: \"+str(num_small_transactions))\n",
    "\n",
    "data = pd.DataFrame(data_small_transactions[\"items\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "for i in range(len(data['items'])):\n",
    "    data_list.append(data['items'][i].split(','))\n",
    "\n",
    "# the data is ready for the apriori algorithm, and we save the data for future use\n",
    "input_file='Apriori_input_small_transactions.txt'\n",
    "with open(input_file,'w') as output:\n",
    "    for key in data_list:\n",
    "        output.write(' '.join([str(item) for item in key])+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> 2. Apriori Algorithm </b>\n",
    "In this section, we implement the Apriori Algorithm to obtain the frequent itemsets. An itemset is frequent if its support count is greater than or equal to a threshold. We sort the single items from largest to smallest support count. The minimum support count among the top 10 percent of single items is our threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = []\n",
    "db_f = []\n",
    "temp = {}\n",
    "candidate = []  # list of candidate after join\n",
    "frequent_Item = []\n",
    "frequent_Item_sorted = {}\n",
    "result_list = {}\n",
    "\n",
    "# read in the data and get all the single items with higher support count than the min_support\n",
    "def construct_L1(file):\n",
    "    filter = {}\n",
    "    count = {}\n",
    "    file = open(file, 'r')\n",
    "    for line in file:  # each line is a transaction\n",
    "        data = set()\n",
    "        for key in line.strip().split(' '):  # get all the elements in the file\n",
    "            if key not in count.keys():\n",
    "                count[key] = 1\n",
    "            else:\n",
    "                count[key] += 1\n",
    "            if count[key] >= min_support_count:\n",
    "                filter[int(key)] = count[key]\n",
    "            data.add(int(key))\n",
    "        db.append(data)\n",
    "    frequent_Item.append(filter)  # items in L1 stored as a dict in the frequent item list\n",
    "\n",
    "\n",
    "# filter the data by removing the set of transaction that does not intersect with the qualified items\n",
    "def filter_db():\n",
    "    global db\n",
    "    global candidate\n",
    "    global temp\n",
    "    keys = sorted(frequent_Item[0].keys())\n",
    "    for transaction in db:\n",
    "        if len(transaction.intersection(keys)) != 0:\n",
    "            db_f.append(sorted(transaction.intersection(keys)))  # now we get filtered data and are ready for next step\n",
    "    candidate = list(itertools.combinations(sorted(frequent_Item[0].keys()), 2))  # construct C2\n",
    "    for key in candidate:\n",
    "        temp[key] = 0\n",
    "    for transaction in db_f:\n",
    "        pool = list(itertools.combinations(transaction, 2))\n",
    "        for combo in pool:\n",
    "            combo = sorted(combo)\n",
    "            combo = tuple(combo)\n",
    "            if temp.get(combo) is not None:\n",
    "                temp[combo] += 1\n",
    "\n",
    "\n",
    "def construct_Lk():\n",
    "    global temp\n",
    "    global Lk\n",
    "    Lk = {}\n",
    "    for key in temp:\n",
    "        if temp.get(key) >= min_support_count:\n",
    "            Lk[key] = temp[key]\n",
    "    frequent_Item.append(Lk)\n",
    "\n",
    "\n",
    "# remove the infrequent items in each transaction\n",
    "def clean(size):\n",
    "    global db_f\n",
    "    keys = list(frequent_Item[size-1])\n",
    "    if len(keys) != 0:\n",
    "        uni = set(keys[0]).union(keys[1])\n",
    "        for i in range(len(keys)-2):\n",
    "            uni = uni.union(keys[i+2])\n",
    "        for j in range(len(db_f)):\n",
    "            db_f[j] = set(db_f[j]).intersection(uni)\n",
    "\n",
    "\n",
    "def aprioriGen(k):\n",
    "    del candidate[:] # ready for new candidate list\n",
    "    temp.clear()\n",
    "    temp_can = []\n",
    "    keys = list(frequent_Item[k-2])\n",
    "    for x in range(len(keys)):\n",
    "        for y in range(x + 1, len(keys)):\n",
    "            L1 = list(keys[x])[:k - 2]\n",
    "            L2 = list(keys[y])[:k - 2]\n",
    "            if L1 == L2:\n",
    "                union = set(keys[x]).union(keys[y])  # set union\n",
    "                temp_can.append(tuple(sorted(union)))\n",
    "    for next_can in temp_can:\n",
    "        can_list = itertools.combinations(next_can, k - 1)  # subset generated from the candidate list for next level\n",
    "        for can in can_list:\n",
    "            if can not in keys:\n",
    "                break\n",
    "        candidate.append(next_can)\n",
    "    for key in candidate:\n",
    "        temp[key] = 0\n",
    "    for transaction in db_f:\n",
    "        pool = list(itertools.combinations(transaction, k))\n",
    "        for combo in pool:\n",
    "            combo = sorted(combo)\n",
    "            combo = tuple(combo)\n",
    "            if temp.get(combo) is not None:\n",
    "                temp[combo] += 1\n",
    "\n",
    "\n",
    "def sort():\n",
    "    global frequent_Item_sorted\n",
    "    global result_list\n",
    "    keys = frequent_Item[0]\n",
    "    for key in keys:\n",
    "        tup = (key,)\n",
    "        frequent_Item_sorted[tup] = keys.get(key)\n",
    "    for i in range(len(frequent_Item)-1):\n",
    "        frequent_Item_sorted.update(frequent_Item[i + 1])\n",
    "    sorted(frequent_Item_sorted)\n",
    "    result_list = collections.OrderedDict(sorted(frequent_Item_sorted.items()))\n",
    "\n",
    "\n",
    "def result(file):\n",
    "    with open(file,'w') as output:\n",
    "        for key in result_list:\n",
    "            output.write(' '.join([str(item) for item in key])+' ({:d})'.format(frequent_Item_sorted[key])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determine the minimum support count of the top 10 percent frequent single items\n",
    "\n",
    "single_items = (data['items'].str.split(\",\", expand=True))\\\n",
    "        .apply(pd.value_counts).sum(axis=1).dropna()\n",
    "\n",
    "single_items_df = pd.DataFrame(single_items,columns=['count'])\n",
    "\n",
    "# calculate the percentage of count of each single item\n",
    "single_items_df['count_percentage'] = single_items_df['count'].apply(lambda x: x/num_small_transactions)\n",
    "\n",
    "# sort the data frame by the percentage of count in descending order\n",
    "single_items_df_2 = single_items_df.sort_values(by=['count_percentage'], ascending=False)\n",
    "\n",
    "# get top 10 percent \n",
    "single_items_df_3 = single_items_df_2[:round(.1*single_items_df_2.shape[0])]\n",
    "\n",
    "# min_support_count = 70\n",
    "min_support_count = int(min(single_items_df_3['count']))\n",
    "min_support_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.109055\n"
     ]
    }
   ],
   "source": [
    "time = datetime.now()\n",
    "global input\n",
    "input = input_file\n",
    "output = 'filtered_result_70.txt'\n",
    "\n",
    "size = 2\n",
    "construct_L1(input)\n",
    "filter_db()\n",
    "while len(candidate) > 0:\n",
    "    construct_Lk()  # find L set and store to frequent item list\n",
    "    clean(size)     # clean database\n",
    "    size += 1\n",
    "    aprioriGen(size)    # generate next level candidate list\n",
    "sort()\n",
    "result(output)\n",
    "print((datetime.now() - time).total_seconds())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = output\n",
    "frequent_set = []\n",
    "support_count = []\n",
    "set_size = []\n",
    "file = open(file, 'r')\n",
    "for line in file:  # each line is a transaction\n",
    "    temp = line.split(' ')\n",
    "    if len(temp[:-1]) == 1:\n",
    "        frequent_set.append(int(temp[:-1][0]))\n",
    "    else:\n",
    "        frequent_set.append(tuple(([int(x) for x in temp[:-1]])))\n",
    "    support_count.append(int(temp[-1][1:-2]))\n",
    "    set_size.append(len(temp)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frequent set</th>\n",
       "      <th>set size</th>\n",
       "      <th>support count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>2</td>\n",
       "      <td>1033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1, 2, 17)</td>\n",
       "      <td>3</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(1, 2, 18)</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(1, 2, 4011)</td>\n",
       "      <td>3</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   frequent set  set size  support count\n",
       "0             1         1           4539\n",
       "1        (1, 2)         2           1033\n",
       "2    (1, 2, 17)         3            254\n",
       "3    (1, 2, 18)         3             88\n",
       "4  (1, 2, 4011)         3            131"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'frequent set':frequent_set,'set size':set_size, 'support count':support_count}\n",
    "df3 = pd.DataFrame(data)\n",
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    894\n",
       "2    447\n",
       "3     67\n",
       "4      3\n",
       "Name: set size, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['set size'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <b> 3. Results </b>\n",
    "Here we take the frequent itemsets and calculate lifts for all possible association rules for frequent itemsets of 2, 3, 4, and 5. <br>\n",
    "<br>\n",
    "lift({X}->{Y}) = lift({Y}->{X}) = P(X,Y)/(P(X)P(Y)) <br>\n",
    "<br>\n",
    "A lift close to 1 means that the occurence of X and the occurence of Y in the same transaction are independent events. \n",
    "So, we use a threshold of 1.5 and identify all association rules with lifts >= 1.5 as strong associations rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lift(both_sides, left_side, right_side):\n",
    "    percent_transactions_containing_both = int(df3[df3[\"frequent set\"] == both_sides][\"support count\"])/int(num_small_transactions)\n",
    "    percent_transactions_containing_left_side = int(df3[df3[\"frequent set\"] == left_side][\"support count\"])/int(num_small_transactions)\n",
    "    percent_transactions_containing_right_side = int(df3[df3[\"frequent set\"] == right_side][\"support count\"])/int(num_small_transactions)\n",
    "    lift = (percent_transactions_containing_both)/(percent_transactions_containing_left_side*percent_transactions_containing_right_side)\n",
    "    return lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate lifts for all possible association rules for frequent itemsets of 2, 3, 4, and 5\n",
    "\n",
    "left_sides = []\n",
    "right_sides = []\n",
    "sizes = []\n",
    "lifts = []\n",
    "for index, row in df3.iterrows():\n",
    "    \n",
    "    if row[\"set size\"] == 2:\n",
    "        atuple = row[\"frequent set\"]\n",
    "        if atuple[0] not in items_descriptions[\"item_id\"].tolist():\n",
    "            print(atuple[0])\n",
    "            pass\n",
    "        if atuple[1] not in items_descriptions[\"item_id\"].tolist():\n",
    "            print(atuple[1])\n",
    "            pass\n",
    "        if atuple[0] in items_descriptions[\"item_id\"].tolist():\n",
    "            if atuple[1] in items_descriptions[\"item_id\"].tolist():\n",
    "                name_0 = items_descriptions.loc[items_descriptions['item_id']==atuple[0],'description'].iloc[0].lower()\n",
    "                name_1 = items_descriptions.loc[items_descriptions['item_id']==atuple[1],'description'].iloc[0].lower()\n",
    "                itemset = (name_0, name_1)\n",
    "                #0->1 and 1->0\n",
    "                left_sides.append(name_0)\n",
    "                right_sides.append(name_1)\n",
    "                sizes.append(2)\n",
    "                lifts.append(calculate_lift(atuple, atuple[0], atuple[1]))\n",
    "        \n",
    "    elif row[\"set size\"] == 3:\n",
    "        atuple = row[\"frequent set\"]\n",
    "        name_0 = items_descriptions.loc[items_descriptions['item_id']==atuple[0],'description'].iloc[0].lower()\n",
    "        name_1 = items_descriptions.loc[items_descriptions['item_id']==atuple[1],'description'].iloc[0].lower()\n",
    "        name_2 = items_descriptions.loc[items_descriptions['item_id']==atuple[2],'description'].iloc[0].lower()\n",
    "        itemset = (name_0, name_1, name_2)\n",
    "        #0->1,2 and 1,2->0\n",
    "        left_sides.append(name_0)\n",
    "        right_sides.append((name_1, name_2))\n",
    "        sizes.append(3)\n",
    "        lifts.append(calculate_lift(atuple, atuple[0], (atuple[1],atuple[2])))\n",
    "        #1->0,2 and 0,2->1\n",
    "        left_sides.append(name_1)\n",
    "        right_sides.append((name_0, name_2))\n",
    "        sizes.append(3)\n",
    "        lifts.append(calculate_lift(atuple, atuple[1], (atuple[0],atuple[2])))\n",
    "        #2->0,1 and 0,1->2\n",
    "        left_sides.append(name_2)\n",
    "        right_sides.append((name_0, name_1))\n",
    "        sizes.append(3)\n",
    "        lifts.append(calculate_lift(atuple, atuple[2], (atuple[0],atuple[1])))\n",
    "        \n",
    "    elif row[\"set size\"] == 4:\n",
    "        atuple = row[\"frequent set\"]\n",
    "        name_0 = items_descriptions.loc[items_descriptions['item_id']==atuple[0],'description'].iloc[0].lower()\n",
    "        name_1 = items_descriptions.loc[items_descriptions['item_id']==atuple[1],'description'].iloc[0].lower()\n",
    "        name_2 = items_descriptions.loc[items_descriptions['item_id']==atuple[2],'description'].iloc[0].lower()\n",
    "        name_3 = items_descriptions.loc[items_descriptions['item_id']==atuple[3],'description'].iloc[0].lower()\n",
    "        itemset = (name_0, name_1, name_2, name_3)\n",
    "        #0->1,2,3 and 1,2,3->0\n",
    "        left_sides.append(name_0)\n",
    "        right_sides.append((name_1, name_2, name_3))\n",
    "        sizes.append(4)\n",
    "        lifts.append(calculate_lift(atuple, atuple[0], (atuple[1],atuple[2],atuple[3])))\n",
    "        #1->0,2,3 and 0,2,3->1\n",
    "        left_sides.append(name_1)\n",
    "        right_sides.append((name_0, name_2, name_3))\n",
    "        sizes.append(4)\n",
    "        lifts.append(calculate_lift(atuple, atuple[1], (atuple[0],atuple[2],atuple[3])))\n",
    "        #2->0,1,3 and 0,1,3->2\n",
    "        left_sides.append(name_2)\n",
    "        right_sides.append((name_0, name_1, name_3))\n",
    "        sizes.append(4)\n",
    "        lifts.append(calculate_lift(atuple, atuple[2], (atuple[0],atuple[1],atuple[3])))\n",
    "        #3->0,1,2 and 0,1,2->3\n",
    "        left_sides.append(name_3)\n",
    "        right_sides.append((name_0, name_1, name_2))\n",
    "        sizes.append(4)\n",
    "        lifts.append(calculate_lift(atuple, atuple[3], (atuple[0],atuple[1],atuple[2])))\n",
    "        #0,1->2,3 and 2,3->0,1\n",
    "        left_sides.append((name_0, name_1))\n",
    "        right_sides.append((name_2, name_3))\n",
    "        sizes.append(4)\n",
    "        lifts.append(calculate_lift(atuple, (atuple[0],atuple[1]), (atuple[2],atuple[3])))\n",
    "        #0,2->1,3 and 1,3->0,2\n",
    "        left_sides.append((name_0, name_2))\n",
    "        right_sides.append((name_1, name_3))\n",
    "        sizes.append(4)\n",
    "        lifts.append(calculate_lift(atuple, (atuple[0],atuple[2]), (atuple[1],atuple[3])))\n",
    "        #0,3->1,2 and 1,2->0,3\n",
    "        left_sides.append((name_0, name_3))\n",
    "        right_sides.append((name_1, name_2))\n",
    "        sizes.append(4)\n",
    "        lifts.append(calculate_lift(atuple, (atuple[0],atuple[3]), (atuple[1],atuple[2])))\n",
    "        \n",
    "    elif row[\"set size\"] == 5:\n",
    "        atuple = row[\"frequent set\"]\n",
    "        name_0 = items_descriptions.loc[items_descriptions['item_id']==atuple[0],'description'].iloc[0].lower()\n",
    "        name_1 = items_descriptions.loc[items_descriptions['item_id']==atuple[1],'description'].iloc[0].lower()\n",
    "        name_2 = items_descriptions.loc[items_descriptions['item_id']==atuple[2],'description'].iloc[0].lower()\n",
    "        name_3 = items_descriptions.loc[items_descriptions['item_id']==atuple[3],'description'].iloc[0].lower()\n",
    "        name_4 = items_descriptions.loc[items_descriptions['item_id']==atuple[4],'description'].iloc[0].lower()\n",
    "        itemset = (name_0, name_1, name_2, name_3, name_4)\n",
    "        #0->1,2,3,4 and 1,2,3,4->0\n",
    "        left_sides.append(name_0)\n",
    "        right_sides.append((name_1, name_2, name_3, name_4))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, atuple[0], (atuple[1],atuple[2],atuple[3],atuple[4])))\n",
    "        #1->0,2,3,4 and 0,2,3,4->1\n",
    "        left_sides.append(name_1)\n",
    "        right_sides.append((name_0, name_2, name_3, name_4))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, atuple[1], (atuple[0],atuple[2],atuple[3],atuple[4])))\n",
    "        #2->0,1,3,4 and 0,1,3,4->2\n",
    "        left_sides.append(name_2)\n",
    "        right_sides.append((name_0, name_1, name_3, name_4))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, atuple[2], (atuple[0],atuple[1],atuple[3],atuple[4])))\n",
    "        #3->0,1,2,4 and 0,1,2,4->3\n",
    "        left_sides.append(name_3)\n",
    "        right_sides.append((name_0, name_1, name_2, name_4))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, atuple[3], (atuple[0],atuple[1],atuple[2],atuple[4])))\n",
    "        #4->0,1,2,3 and 0,1,2,3->4\n",
    "        left_sides.append(name_4)\n",
    "        right_sides.append((name_0, name_1, name_2, name_3))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, atuple[4], (atuple[0],atuple[1],atuple[2],atuple[3])))\n",
    "        #0,1->2,3,4 and 2,3,4->0,1\n",
    "        left_sides.append((name_0, name_1))\n",
    "        right_sides.append((name_2, name_3, name_4))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, (atuple[0],atuple[1]), (atuple[2],atuple[3],atuple[4])))\n",
    "        #0,2->1,3,4 and 1,3,4->0,2\n",
    "        left_sides.append((name_0, name_2))\n",
    "        right_sides.append((name_1, name_3, name_4))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, (atuple[0],atuple[2]), (atuple[1],atuple[3],atuple[4])))\n",
    "        #0,3->1,2,4 and 1,2,4->0,3\n",
    "        left_sides.append((name_0, name_3))\n",
    "        right_sides.append((name_1, name_2, name_4))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, (atuple[0],atuple[3]), (atuple[1],atuple[2],atuple[4])))\n",
    "        #0,4->1,2,3 and 1,2,3->0,4\n",
    "        left_sides.append((name_0, name_4))\n",
    "        right_sides.append((name_1, name_2, name_3))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, (atuple[0],atuple[4]), (atuple[1],atuple[2],atuple[3])))\n",
    "        #1,2->0,3,4 and 0,3,4->1,2\n",
    "        left_sides.append((name_1, name_2))\n",
    "        right_sides.append((name_0, name_3, name_4))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, (atuple[1],atuple[2]), (atuple[0],atuple[3],atuple[4])))\n",
    "        #1,3->0,2,4 and 0,2,4->1,3\n",
    "        left_sides.append((name_1, name_3))\n",
    "        right_sides.append((name_0, name_2, name_4))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, (atuple[1],atuple[3]), (atuple[0],atuple[2],atuple[4])))\n",
    "        #1,4->0,2,3 and 0,2,3->1,4\n",
    "        left_sides.append((name_1, name_4))\n",
    "        right_sides.append((name_0, name_2, name_3))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, (atuple[1],atuple[4]), (atuple[0],atuple[2],atuple[3])))\n",
    "        #2,3->0,1,4 and 0,1,4->2,3\n",
    "        left_sides.append((name_2, name_3))\n",
    "        right_sides.append((name_0, name_1, name_4))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, (atuple[2],atuple[3]), (atuple[0],atuple[1],atuple[4])))\n",
    "        #2,4->0,1,3 and 0,1,3->2,4\n",
    "        left_sides.append((name_2, name_4))\n",
    "        right_sides.append((name_0, name_1, name_3))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, (atuple[2],atuple[4]), (atuple[0],atuple[1],atuple[3])))\n",
    "        #3,4->0,1,2 and 0,1,2->3,4\n",
    "        left_sides.append((name_3, name_4))\n",
    "        right_sides.append((name_0, name_1, name_2))\n",
    "        sizes.append(5)\n",
    "        lifts.append(calculate_lift(atuple, (atuple[3],atuple[4]), (atuple[0],atuple[1],atuple[2])))\n",
    "\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left side</th>\n",
       "      <th>right side</th>\n",
       "      <th>set size</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pan dulce sencillo</td>\n",
       "      <td>bolillo french rolls</td>\n",
       "      <td>2</td>\n",
       "      <td>1.949890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pan dulce sencillo</td>\n",
       "      <td>(bolillo french rolls, premium sweet bread)</td>\n",
       "      <td>3</td>\n",
       "      <td>9.474194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bolillo french rolls</td>\n",
       "      <td>(pan dulce sencillo, premium sweet bread)</td>\n",
       "      <td>3</td>\n",
       "      <td>2.064729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>premium sweet bread</td>\n",
       "      <td>(pan dulce sencillo, bolillo french rolls)</td>\n",
       "      <td>3</td>\n",
       "      <td>9.088518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pan dulce sencillo</td>\n",
       "      <td>(bolillo french rolls, pan dulce figura/tapado)</td>\n",
       "      <td>3</td>\n",
       "      <td>11.422745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              left side                                       right side  \\\n",
       "0    pan dulce sencillo                             bolillo french rolls   \n",
       "1    pan dulce sencillo      (bolillo french rolls, premium sweet bread)   \n",
       "2  bolillo french rolls        (pan dulce sencillo, premium sweet bread)   \n",
       "3   premium sweet bread       (pan dulce sencillo, bolillo french rolls)   \n",
       "4    pan dulce sencillo  (bolillo french rolls, pan dulce figura/tapado)   \n",
       "\n",
       "   set size       lift  \n",
       "0         2   1.949890  \n",
       "1         3   9.474194  \n",
       "2         3   2.064729  \n",
       "3         3   9.088518  \n",
       "4         3  11.422745  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'left side': left_sides, 'right side': right_sides, 'set size': sizes, 'lift': lifts})\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(490, 4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_associations = results[results[\"lift\"]>=1.5]\n",
    "strong_associations.sort_values(by=\"lift\", ascending=False, inplace=True)\n",
    "# 490 strong associations\n",
    "strong_associations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left side</th>\n",
       "      <th>right side</th>\n",
       "      <th>set size</th>\n",
       "      <th>lift</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>*pepper- bell red</td>\n",
       "      <td>*pepper bell yellow</td>\n",
       "      <td>2</td>\n",
       "      <td>180.592754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>*peppers-bell green</td>\n",
       "      <td>*pepper- bell red</td>\n",
       "      <td>2</td>\n",
       "      <td>82.905253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>costillas de puerco/spareribs</td>\n",
       "      <td>trocitos frescos de puerco</td>\n",
       "      <td>2</td>\n",
       "      <td>48.845872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>*squash chayote</td>\n",
       "      <td>*squash-mexican</td>\n",
       "      <td>2</td>\n",
       "      <td>44.087182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>*carrots loose</td>\n",
       "      <td>*squash chayote</td>\n",
       "      <td>2</td>\n",
       "      <td>34.625853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>665</th>\n",
       "      <td>wedges fries/papas fritas</td>\n",
       "      <td>chicken tenders</td>\n",
       "      <td>2</td>\n",
       "      <td>27.474753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>frijoles fritos/refried beans</td>\n",
       "      <td>arroz/fried rice</td>\n",
       "      <td>2</td>\n",
       "      <td>22.926352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>beef marinated flap meat</td>\n",
       "      <td>costillas de res para asar</td>\n",
       "      <td>2</td>\n",
       "      <td>22.472028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>666</th>\n",
       "      <td>ceviche de camaron</td>\n",
       "      <td>camaron aguachile verde</td>\n",
       "      <td>2</td>\n",
       "      <td>21.691702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>beef marinated flap meat</td>\n",
       "      <td>prna pllo adbda/mrntd leg meat</td>\n",
       "      <td>2</td>\n",
       "      <td>20.736466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         left side                      right side  set size  \\\n",
       "550              *pepper- bell red             *pepper bell yellow         2   \n",
       "449            *peppers-bell green               *pepper- bell red         2   \n",
       "639  costillas de puerco/spareribs      trocitos frescos de puerco         2   \n",
       "616                *squash chayote                 *squash-mexican         2   \n",
       "595                 *carrots loose                 *squash chayote         2   \n",
       "665      wedges fries/papas fritas                 chicken tenders         2   \n",
       "647  frijoles fritos/refried beans                arroz/fried rice         2   \n",
       "636       beef marinated flap meat      costillas de res para asar         2   \n",
       "666             ceviche de camaron         camaron aguachile verde         2   \n",
       "637       beef marinated flap meat  prna pllo adbda/mrntd leg meat         2   \n",
       "\n",
       "           lift  \n",
       "550  180.592754  \n",
       "449   82.905253  \n",
       "639   48.845872  \n",
       "616   44.087182  \n",
       "595   34.625853  \n",
       "665   27.474753  \n",
       "647   22.926352  \n",
       "636   22.472028  \n",
       "666   21.691702  \n",
       "637   20.736466  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_associations.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(282, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract strong associations from itemsets of 2\n",
    "strong_associations_itemsets_2 = strong_associations[strong_associations[\"set size\"] == 2]\n",
    "# 282 strong associations from itemsets of 2\n",
    "strong_associations_itemsets_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract strong associations from itemsets of 3\n",
    "strong_associations_itemsets_3 = strong_associations[strong_associations[\"set size\"] == 3]\n",
    "# 187 strong associations from itemsets of 3\n",
    "strong_associations_itemsets_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract strong associations from itemsets of 4\n",
    "strong_associations_itemsets_4 = strong_associations[strong_associations[\"set size\"] == 4]\n",
    "# 21 strong associations from itemsets of 4\n",
    "strong_associations_itemsets_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract strong associations from itemsets of 5\n",
    "strong_associations_itemsets_5 = strong_associations[strong_associations[\"set size\"] == 5]\n",
    "# 0 strong associations from itemsets of 5\n",
    "strong_associations_itemsets_5.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
